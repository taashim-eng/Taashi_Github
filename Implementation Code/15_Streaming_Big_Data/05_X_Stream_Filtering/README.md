# X (Twitter): Firehose Filtering & Decoupling

## 1. Problem Statement
X processes 500 million posts per day. It is impossible and wasteful for a single analytics service (e.g., one analyzing 'AI Trends') to ingest *every single post* about cats, sports, and politics just to find the 1% of data it needs.

## 2. Requirements & KPIs
- Ingestion Scale: Handle erratic bursts of traffic (e.g., during the Super Bowl).
- Filtering: Discard irrelevant data at the edge (Consumer) before processing.
- Decoupling: The 'Sports' service should not crash if the 'Politics' stream spikes.
- Latency: Real-time keyword matching.

## 3. Architecture & Pipeline
1. **Firehose (Producer)**: A massive, unorganized stream of all public posts.
2. **Ingestion**: Kafka Topic `global-firehose` (partitioned by User ID).
3. **Filter Engine (Consumer)**: 
   - Reads the full stream.
   - Applies `WHERE topic = 'Tech'` logic.
   - Discards 90% of noise silently.
4. **Downstream**: Only relevant events are saved to the database.

---

## 4. Technical Implementation

### File Structure
- `producer.py`: The "Firehose". Generates a high-speed stream of random topics.
- `consumer.py`: The "Filter". It ignores everything except specific keywords (AI, Tech).
- `utils_logger.py`: Logging config.

### How to Run this Demo

**Step 1: Install Dependencies**
```bash
pip install -r requirements.txt
```

**Step 2: Start the Filter Engine (Consumer)**
This service represents a specific team (e.g., the AI Analytics Team) looking for data.
```bash
python consumer.py
```
*Observe that it ONLY prints tweets that match its interest profile, ignoring the rest.*

**Step 3: Start the Firehose (Producer)**
This simulates the global stream of all user activity.
```bash
python producer.py
```
*Warning: This will generate a lot of noise in the terminal to simulate high volume.*

**Step 4: Analyze the Difference**
- The **Producer** terminal is chaos (Sports, K-Pop, Politics).
- The **Consumer** terminal is clean (Only Tech/AI updates).
- This demonstrates how **Stream Filtering** saves compute resources downstream.

---
*Generated by Automation Script | X (Twitter): Firehose Filtering & Decoupling Project*