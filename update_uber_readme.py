import os

# ==========================================
# CONFIGURATION: Uber CDC Use Case
# ==========================================
project_config = {
    "title": "Uber Style: CDC Data Mesh (Change Data Capture)",
    "problem_statement": (
        "In a massive monolith (like Uber's early days), querying the main database for "
        "analytics or driver incentives slows down the app for everyone. "
        "We need to 'stream' database changes instantly to microservices without "
        "hitting the main database with heavy queries."
    ),
    "requirements": [
        "Uncouple Microservices: The Incentive Service should not query the Main DB directly.",
        "Real-Time: Database changes (Inserts/Updates) must propagate in < 500ms.",
        "Event Format: Use standard CDC format (Operation, Before, After).",
        "Business Logic: Instantly trigger 'Bonus Unlocked' events when thresholds are met."
    ],
    "pipeline_description": (
        "1. **Source (Monolith)**: PostgreSQL Database (Users, Trips).\n"
        "2. **Capture (Producer)**: Simulates Debezium reading the Write-Ahead Log (WAL).\n"
        "3. **Transport**: Kafka Topic `db-changes.public.drivers`.\n"
        "4. **Sink (Consumer)**: Incentive Service builds a local 'Mesh' state to calculate bonuses."
    ),
    "instructions": "python producer.py"
}

# ==========================================
# LOGIC: README Generator
# ==========================================
def generate_readme():
    target_path = "/workspaces/Taashi_Github/Implementation Code/15_Streaming_Big_Data/02_Uber_CDC_Mesh"
    
    # 1. Ensure directory exists
    os.makedirs(target_path, exist_ok=True)
    file_path = os.path.join(target_path, "README.md")
    
    # 2. Formatting Helpers
    req_list = "\n".join([f"- {req}" for req in project_config['requirements']])
    B_BASH = "```bash"
    B_END = "```"
    
    # 3. Construct Content
    content = f"""
# {project_config['title']}

## 1. Problem Statement
{project_config['problem_statement']}

## 2. Requirements & KPIs
{req_list}

## 3. Architecture & Pipeline
{project_config['pipeline_description']}

---

## 4. Technical Implementation

### File Structure
- `producer.py`: Simulates the CDC Process (Debezium) emitting WAL events.
- `consumer.py`: The Downstream Microservice (Incentives) consuming the stream.
- `utils_logger.py`: Logging utility.
- `.env`: Environment config.

### How to Run this Demo

**Step 1: Install Dependencies**
{B_BASH}
pip install -r requirements.txt
{B_END}

**Step 2: Start the Microservice (Consumer)**
This service acts as a Data Mesh node. It listens for DB changes to update its local cache.
{B_BASH}
python consumer.py
{B_END}
*It will start waiting for database events...*

**Step 3: Start the Database Simulator (Producer)**
This script generates random Insert/Update/Delete events as if users are taking trips.
{B_BASH}
{project_config['instructions']}
{B_END}

**Step 4: Observe Real-Time Sync**
Watch the Consumer terminal. You will see:
- ðŸ”„ **Syncing Trip Data**: Updates the local cache.
- â­ **Rating Update**: Updates driver scores.
- ðŸ’° **BONUS UNLOCKED**: When logic (Trips > 15 & Rating > 4.8) is met.

---
*Generated by Automation Script | {project_config['title']} Project*
"""

    with open(file_path, "w") as f:
        f.write(content.strip())
    
    print(f"âœ… README successfully written to:\n   {file_path}")

if __name__ == "__main__":
    generate_readme()