# X (Twitter): Firehose Filtering & Decoupling

## 1. Problem Statement
X processes 500 million posts per day. It is impossible and wasteful for a single analytics service (e.g., one analyzing 'AI Trends') to ingest *every single post* about cats, sports, and politics just to find the 1% of data it needs.

## 2. Requirements & KPIs
- Ingestion Scale: Handle erratic bursts of traffic (e.g., during the Super Bowl).
- Filtering: Discard irrelevant data at the edge (Consumer) before processing.
- Decoupling: The 'Sports' service should not crash if the 'Politics' stream spikes.
- Latency: Real-time keyword matching.

## 3. Architecture & Pipeline
1. **Firehose (Producer)**: A massive, unorganized stream of all public posts.
2. **Ingestion**: Kafka Topic `global-firehose` (partitioned by User ID).
3. **Filter Engine (Consumer)**: 
   - Reads the full stream.
   - Applies `WHERE topic = 'Tech'` logic.
   - Discards 90% of noise silently.
4. **Downstream**: Only relevant events are saved to the database.

---

## 4. Technical Implementation

### File Structure
- `producer.py`: The "Firehose". Generates a high-speed stream of random topics.
- `consumer.py`: The "Filter". It ignores everything except specific keywords (AI, Tech).
- `utils_logger.py`: Logging config.

### Architecture Diagram: X (Twitter) Firehose Filtering

```mermaid
%%{init: {'theme': 'neutral', 'themeVariables': { 'fontFamily': 'arial', 'fontSize': '14px'}}}%%
graph TD
    %% Definitions & Styling
    classDef source fill:#E1D5E7,stroke:#9673A6,stroke-width:2px,color:#000;
    classDef ingestion fill:#FFF2CC,stroke:#D6B656,stroke-width:2px,color:#000;
    classDef processing fill:#DAE8FC,stroke:#6C8EBF,stroke-width:2px,color:#000;
    classDef action fill:#D5E8D4,stroke:#82B366,stroke-width:2px,color:#000;
    classDef waste fill:#F5F5F5,stroke:#666666,stroke-width:2px,color:#999,stroke-dasharray: 5 5;

    subgraph Sources ["Global Data Sources"]
        Users["Global Users<br/>(500M Tweets/Day)"]:::source
        Topics["Diverse Topics<br/>(Sports, Politics, K-Pop)"]:::source
    end

    subgraph Ingestion ["The Firehose (High Volume)"]
        Kafka["Apache Kafka<br/>Topic: global-firehose"]:::ingestion
    end

    subgraph Filtering ["Filter Engine (Consumer)"]
        FilterService["Stream Processor<br/>(Python/Spark)"]:::processing
        LogicGate{"Contains Keywords?<br/>(#AI, #Tech)"}:::processing
    end

    subgraph Destinations ["Downstream Actions"]
        AnalyticsDB[("Tech Analytics DB<br/>(High Value Data)")]:::action
        Discard["/dev/null<br/>(Discard Noise)"]:::waste
    end

    %% Data Flow
    Users -->|"Emit Tweets"| Kafka
    Topics -.->|"Context"| Users
    Kafka -->|"Consume Full Stream"| FilterService
    
    FilterService -->|"Apply Rules"| LogicGate

    %% Decision Logic
    LogicGate -->|"Yes (Match)"| AnalyticsDB
    LogicGate -->|"No (Irrelevant)"| Discard

    linkStyle 2,3,4,5,6 stroke:#007ACC,stroke-width:2px,fill:none;
```


### How to Run this Demo

**Step 1: Install Dependencies**
```bash
pip install -r requirements.txt
```

**Step 2: Start the Filter Engine (Consumer)**
This service represents a specific team (e.g., the AI Analytics Team) looking for data.
```bash
python consumer.py
```
*Observe that it ONLY prints tweets that match its interest profile, ignoring the rest.*

**Step 3: Start the Firehose (Producer)**
This simulates the global stream of all user activity.
```bash
python producer.py
```
*Warning: This will generate a lot of noise in the terminal to simulate high volume.*

**Step 4: Analyze the Difference**
- The **Producer** terminal is chaos (Sports, K-Pop, Politics).
- The **Consumer** terminal is clean (Only Tech/AI updates).
- This demonstrates how **Stream Filtering** saves compute resources downstream.

---
*Generated by Automation Script | X (Twitter): Firehose Filtering & Decoupling Project*
